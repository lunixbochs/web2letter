<!DOCTYPE html>
<html>
<head>
<title>web2letter demo</title>
<script type="text/javascript">
// vad from https://github.com/kdavis-mozilla/vad.js
/*
Copyright (c) 2015, Kelly Davis
All rights reserved.

Redistribution and use in source and binary forms, with or without modification,
are permitted provided that the following conditions are met:

* Redistributions of source code must retain the above copyright notice, this
  list of conditions and the following disclaimer.

* Redistributions in binary form must reproduce the above copyright notice, this
  list of conditions and the following disclaimer in the documentation and/or
  other materials provided with the distribution.

* Neither the name of the {organization} nor the names of its
  contributors may be used to endorse or promote products derived from
  this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR
ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/
var VAD = function(options) {
    // Default options
    this.options = {
        fftSize: 512,
        bufferLen: 512, 
        voice_stop: function() {},
        voice_start: function() {},
        smoothingTimeConstant: 0.99, 
        energy_offset: 1e-8, // The initial offset.
        energy_threshold_ratio_pos: 2, // Signal must be twice the offset
        energy_threshold_ratio_neg: 0.5, // Signal must be half the offset
        energy_integration: 1, // Size of integration change compared to the signal per second.
        filter: [
            {f: 200, v:0}, // 0 -> 200 is 0
            {f: 2000, v:1} // 200 -> 2k is 1
        ],
        source: null,
        context: null
    };

    // User options
    for(var option in options) {
        if(options.hasOwnProperty(option)) {
            this.options[option] = options[option];
        }
    }

    // Require source
    if(!this.options.source)
        throw new Error("The options must specify a MediaStreamAudioSourceNode.");

    // Set this.options.context
    this.options.context = this.options.source.context;

    // Calculate time relationships
    this.hertzPerBin = this.options.context.sampleRate / this.options.fftSize;
    this.iterationFrequency = this.options.context.sampleRate / this.options.bufferLen;
    this.iterationPeriod = 1 / this.iterationFrequency;

    var DEBUG = true;
    if(DEBUG) console.log(
        'Vad' +
        ' | sampleRate: ' + this.options.context.sampleRate +
        ' | hertzPerBin: ' + this.hertzPerBin +
        ' | iterationFrequency: ' + this.iterationFrequency +
        ' | iterationPeriod: ' + this.iterationPeriod
    );

    this.setFilter = function(shape) {
        this.filter = [];
        for(var i = 0, iLen = this.options.fftSize / 2; i < iLen; i++) {
            this.filter[i] = 0;
            for(var j = 0, jLen = shape.length; j < jLen; j++) {
                if(i * this.hertzPerBin < shape[j].f) {
                    this.filter[i] = shape[j].v;
                    break; // Exit j loop
                }
            }
        }
    }

    this.setFilter(this.options.filter);

    this.ready = {};
    this.vadState = false; // True when Voice Activity Detected

    // Energy detector props
    this.energy_offset = this.options.energy_offset;
    this.energy_threshold_pos = this.energy_offset * this.options.energy_threshold_ratio_pos;
    this.energy_threshold_neg = this.energy_offset * this.options.energy_threshold_ratio_neg;

    this.voiceTrend = 0;
    this.voiceTrendMax = 10;
    this.voiceTrendMin = -10;
    this.voiceTrendStart = 5;
    this.voiceTrendEnd = -5;

    // Create analyser 
    this.analyser = this.options.context.createAnalyser();
    this.analyser.smoothingTimeConstant = this.options.smoothingTimeConstant; // 0.99;
    this.analyser.fftSize = this.options.fftSize;

    this.floatFrequencyData = new Float32Array(this.analyser.frequencyBinCount);

    // Setup local storage of the Linear FFT data
    this.floatFrequencyDataLinear = new Float32Array(this.floatFrequencyData.length);

    // Connect this.analyser
    this.options.source.connect(this.analyser); 

    // Create ScriptProcessorNode
    this.scriptProcessorNode = this.options.context.createScriptProcessor(this.options.bufferLen, 1, 1);

    // Connect scriptProcessorNode (Theretically, not required)
    this.scriptProcessorNode.connect(this.options.context.destination);

    // Create callback to update/analyze floatFrequencyData
    var self = this;
    this.scriptProcessorNode.onaudioprocess = function(event) {
        self.analyser.getFloatFrequencyData(self.floatFrequencyData);
        self.update();
        self.monitor();
    };

    // Connect scriptProcessorNode
    this.options.source.connect(this.scriptProcessorNode);

    // log stuff
    this.logging = false;
    this.log_i = 0;
    this.log_limit = 100;

    this.triggerLog = function(limit) {
        this.logging = true;
        this.log_i = 0;
        this.log_limit = typeof limit === 'number' ? limit : this.log_limit;
    }

    this.log = function(msg) {
        if(this.logging && this.log_i < this.log_limit) {
            this.log_i++;
            console.log(msg);
        } else {
            this.logging = false;
        }
    }

    this.update = function() {
        // Update the local version of the Linear FFT
        var fft = this.floatFrequencyData;
        for(var i = 0, iLen = fft.length; i < iLen; i++) {
            this.floatFrequencyDataLinear[i] = Math.pow(10, fft[i] / 10);
        }
        this.ready = {};
    }

    this.getEnergy = function() {
        if(this.ready.energy) {
            return this.energy;
        }

        var energy = 0;
        var fft = this.floatFrequencyDataLinear;

        for(var i = 0, iLen = fft.length; i < iLen; i++) {
            energy += this.filter[i] * fft[i] * fft[i];
        }

        this.energy = energy;
        this.ready.energy = true;

        return energy;
    }

    this.monitor = function() {
        var energy = this.getEnergy();
        var signal = energy - this.energy_offset;

        if(signal > this.energy_threshold_pos) {
            this.voiceTrend = (this.voiceTrend + 1 > this.voiceTrendMax) ? this.voiceTrendMax : this.voiceTrend + 1;
        } else if(signal < -this.energy_threshold_neg) {
            this.voiceTrend = (this.voiceTrend - 1 < this.voiceTrendMin) ? this.voiceTrendMin : this.voiceTrend - 1;
        } else {
            // voiceTrend gets smaller
            if(this.voiceTrend > 0) {
                this.voiceTrend--;
            } else if(this.voiceTrend < 0) {
                this.voiceTrend++;
            }
        }

        var start = false, end = false;
        if(this.voiceTrend > this.voiceTrendStart) {
            // Start of speech detected
            start = true;
        } else if(this.voiceTrend < this.voiceTrendEnd) {
            // End of speech detected
            end = true;
        }

        // Integration brings in the real-time aspect through the relationship with the frequency this functions is called.
        var integration = signal * this.iterationPeriod * this.options.energy_integration;

        // Idea?: The integration is affected by the voiceTrend magnitude? - Not sure. Not doing atm.

        // The !end limits the offset delta boost till after the end is detected.
        if(integration > 0 || !end) {
            this.energy_offset += integration;
        } else {
            this.energy_offset += integration * 10;
        }
        this.energy_offset = this.energy_offset < 0 ? 0 : this.energy_offset;
        this.energy_threshold_pos = this.energy_offset * this.options.energy_threshold_ratio_pos;
        this.energy_threshold_neg = this.energy_offset * this.options.energy_threshold_ratio_neg;

        // Broadcast the messages
        if(start && !this.vadState) {
            this.vadState = true;
            this.options.voice_start();
        }
        if(end && this.vadState) {
            this.vadState = false;
            this.options.voice_stop();
        }

        this.log(
            'e: ' + energy +
            ' | e_of: ' + this.energy_offset +
            ' | e+_th: ' + this.energy_threshold_pos +
            ' | e-_th: ' + this.energy_threshold_neg +
            ' | signal: ' + signal +
            ' | int: ' + integration +
            ' | voiceTrend: ' + this.voiceTrend +
            ' | start: ' + start +
            ' | end: ' + end
        );

        return signal;
    }
};

var audio_context;
var input;
var vad;
var node;
var samples = [];

function message(text) {
    var message = document.getElementById('message');
    message.innerHTML = text;
}

function gotUserMedia(localMediaStream) {
    message('success grabbing microphone');
    container.stream = localMediaStream;
    if (!audio_context) {
        if (typeof webkitAudioContext !== 'undefined') {
            audio_context = new webkitAudioContext({sampleRate: 16000});
        } else if (typeof AudioContext !== 'undefined') {
            audio_context = new AudioContext({sampleRate: 16000});
        } else {
            message('Browser does not support AudioContext interface');
            alert(
                'Could not start recording audio:\n Web Audio is not supported by your browser!',
            );
            return;
        }
        if (!audio_context) {
            message("could not make audio context " + audio_context.toString());
            return;
        }
    }
    input = audio_context.createMediaStreamSource(localMediaStream);

    if (input.context.createJavaScriptNode)
        node = input.context.createJavaScriptNode(512, 1, 1);
    else if (input.context.createScriptProcessor)
        node = input.context.createScriptProcessor(512, 1, 1);
    else {
        message('could not create audio node');
        return;
    }

    node.onaudioprocess = function(e) {
        var mono = e.inputBuffer.getChannelData(0);
        mono = Array.prototype.slice.call(mono);
        samples = samples.concat(mono);
    };

    input.connect(node);
    node.connect(audio_context.destination)

    setTimeout(function() {
        var msg = document.getElementById('message');
        if (msg.innerHTML = 'loading')
            message('waiting for speech');
    }, 2500);
    var options = {
        source: input,
        sampleRate: 16000,
        voice_start: function() {
            message('speech active');
            samples = samples.slice(samples.length - 16000);
        },
        voice_stop: function() {
            message('waiting for server');
            fetch('/decode', {
                headers: { "Content-Type": "application/json; charset=utf-8" },
                method: 'POST',
                body: JSON.stringify({
                    samples: samples,
                })
            }).then(response => response.text())
            .then(response => {
                var data = JSON.parse(response);
                document.getElementById('emit').innerHTML = data.emit;
                document.getElementById('decode').innerHTML = data.decode.join(' ');
                message('waiting for speech');
            }).catch(response => message('error from server: ' + response));
            samples = [];
        },
    };
    vad = new VAD(options);

    var button = document.getElementById('record');
    button.innerHTML = 'stop';
    button.onclick = function() {
        window.location = window.location;
    }
}

function userMediaFailed(e) {
    message('failed to open microphone: ' + e);
}

function record() {
    message('requesting microphone access');
    if (navigator.mediaDevices.getUserMedia) {
        navigator.mediaDevices.getUserMedia({ video: false, audio: true })
            .then(gotUserMedia)
            .catch(userMediaFailed);
    } else if (navigator.webkitGetUserMedia) {
        navigator.webkitGetUserMedia(
            { video: false, audio: true },
            gotUserMedia,
            userMediaFailed,
        );
    } else if (navigator.mozGetUserMedia) {
        navigator.mozGetUserMedia(
            { video: false, audio: true },
            gotUserMedia,
            userMediaFailed,
        );
    } else {
        navigator.getUserMedia(
            { video: false, audio: true },
            gotUserMedia,
            userMediaFailed,
        );
    }
}
</script>
<style type="text/css">
#container {
    padding-top: 100px;
    width: 500px;
    margin: auto;
    text-align: center;
}
button {
    padding: 0px 25px 5px 25px;
    font-size: 20pt;
    margin: auto;
    display: block;
}
#message, #emit, #decode {
    font-size: 15pt;
    text-align: center;
}
#emit, #decode {
    margin-top: 10px;
    font-size: 25pt;
}
#message, #emit {
    font-style: italic;
}
.spacer {
    margin-top: 15px;
}
</style>
</head>
<body>
    <div id="container">
        <h1>web2letter</h1>
        <h2>made by <a href="https://talonvoice.com">Talon Voice</a></h2>
        <button id="record" onclick="record()">record</button>
        <div class="spacer"></div>
        <div id="message"></div>
        <div id="decode"></div>
        <div id="emit"></div>
    </div>
</body>
</html>
